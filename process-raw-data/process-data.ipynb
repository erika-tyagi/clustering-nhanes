{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import functools\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_FILE = 'NHANES-varnames_raw.xlsx'\n",
    "NO_FLAG_FILE = 'NHANES-varnames_noflag.csv'\n",
    "YES_FLAG_FILE = 'NHANES-varnames_yesflag.csv'\n",
    "CLEAN_FILE = 'NHANES-clean.csv'\n",
    "MISSING_FILE = 'NHANES-missing.csv'\n",
    "\n",
    "COMPONENTS = ['Laboratory', 'Demographics', 'Questionnaire', 'Dietary', 'Examination']\n",
    "\n",
    "YEARS = list(range(2003, 2016, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw file and append sheets \n",
    "no_flag_df = pd.DataFrame()\n",
    "for c in COMPONENTS: \n",
    "    df = pd.read_excel(RAW_FILE, sheet_name = c)\n",
    "    no_flag_df = no_flag_df.append(df)\n",
    "    \n",
    "# create year flags \n",
    "def var_in_year(row, year): \n",
    "    if (row['Begin Year'] <= year) & (row['EndYear'] >= year): \n",
    "        return 1\n",
    "    return 0 \n",
    "\n",
    "for y in YEARS: \n",
    "    v = 'flag_' + str(y)\n",
    "    no_flag_df[v] = no_flag_df.apply(var_in_year, year = y, axis = 1)\n",
    "    \n",
    "flags = [col for col in no_flag_df if col.startswith('flag_')]\n",
    "no_flag_df = (no_flag_df\n",
    "              .groupby(['Variable Name', \n",
    "                        'Variable Description', \n",
    "                        'Component', \n",
    "                        'Data File Description'])[flags]\n",
    "              .sum(axis = 1)\n",
    "              .reset_index())\n",
    "\n",
    "for y in YEARS: \n",
    "    v = 'flag_' + str(y)\n",
    "    no_flag_df[v] = np.where(no_flag_df[v] == 0, 0, 1)\n",
    "\n",
    "# write to csv\n",
    "no_flag_df.to_csv(NO_FLAG_FILE, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003\n",
      "Laboratory\n",
      "Demographics\n",
      "Questionnaire\n",
      "Dietary\n",
      "Examination\n",
      "2005\n",
      "Laboratory\n",
      "Demographics\n",
      "Questionnaire\n",
      "Dietary\n",
      "Examination\n",
      "2007\n",
      "Laboratory\n",
      "Demographics\n",
      "Questionnaire\n",
      "Dietary\n",
      "Examination\n",
      "2009\n",
      "Laboratory\n",
      "Demographics\n",
      "Questionnaire\n",
      "Dietary\n",
      "Examination\n",
      "2011\n",
      "Laboratory\n",
      "Demographics\n",
      "Questionnaire\n",
      "Dietary\n",
      "Examination\n",
      "2013\n",
      "Laboratory\n",
      "Demographics\n",
      "Questionnaire\n",
      "Dietary\n",
      "Examination\n",
      "2015\n",
      "Laboratory\n",
      "Demographics\n",
      "Questionnaire\n",
      "Dietary\n",
      "Examination\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'DR1TKCAL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'DR1TKCAL'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-776b91c7f867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mclean_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DR1'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclean_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DR2'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mclean_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TKCAL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     clean_df = clean_df.drop(columns = ['DR1' + i, \n\u001b[1;32m     58\u001b[0m                                         'DR2' + i])\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'DR1TKCAL'"
     ]
    }
   ],
   "source": [
    "# get list of variables to keep \n",
    "yes_flag_df = pd.read_csv(YES_FLAG_FILE)\n",
    "keep_vars = (yes_flag_df[yes_flag_df['keep'] == 1]['Variable Name']\n",
    "             .unique()\n",
    "             .tolist())\n",
    "keep_vars = set(keep_vars)\n",
    "\n",
    "# loop over all years and components \n",
    "full_df_list = []\n",
    "for y in YEARS:\n",
    "    print(y)\n",
    "    year_df_list = []\n",
    "    for c in COMPONENTS: \n",
    "        print(c)\n",
    "        path = 'csv_data/' + str(y) + '-' + str(y+1) + '/' + c + '/*.csv'\n",
    "        for f in glob.iglob(path):\n",
    "            df = pd.read_csv(f)\n",
    "            df = df[df.columns[df.columns.isin(keep_vars)]]\n",
    "            if (df.shape[1] > 1) & ('SEQN' in df.columns): \n",
    "                year_df_list.append(df)\n",
    "                \n",
    "    #merge (wide) within each year\n",
    "    year_df = (functools.reduce(\n",
    "        lambda df1, df2: pd.merge(df1, df2, on = 'SEQN', how = 'outer'), year_df_list)\n",
    "               .drop_duplicates(subset = 'SEQN')) \n",
    "    year_df['year'] = str(y) + '-' + str(y+1)\n",
    "    year_df = year_df.loc[:,~year_df.columns.duplicated()]\n",
    "    full_df_list.append(year_df)\n",
    "\n",
    "# append (long) across years \n",
    "clean_df = pd.concat(full_df_list, axis = 0, sort = True)\n",
    "\n",
    "# combine DRSTZ variables \n",
    "clean_df['DR1DRSTZ'] = np.where(clean_df['DR1DRSTZ_x'].notna(), \n",
    "                                clean_df['DR1DRSTZ_x'], clean_df['DR1DRSTZ_y'])\n",
    "clean_df['DR2DRSTZ'] = np.where(clean_df['DR2DRSTZ_x'].notna(), \n",
    "                                clean_df['DR2DRSTZ_x'], clean_df['DR2DRSTZ_y'])\n",
    "clean_df = clean_df.drop(columns = ['DR1DRSTZ_x', 'DR1DRSTZ_y', \n",
    "                                    'DR2DRSTZ_x', 'DR2DRSTZ_y'])\n",
    "\n",
    "# combine day 1 and day 2 variables - based on DR1 and DR2 prefixes \n",
    "exclude_cols = ['year', 'SEQN', \n",
    "                'DR1DRSTZ','DR2DRSTZ', \n",
    "                'DR1_300', 'DR2_300', \n",
    "                'RIDAGEYR', 'RIAGENDR', 'INDFMPIR', 'RIDRETH1', 'BMXBMI','BPQ020']\n",
    "\n",
    "feature_cols = set()\n",
    "for i in clean_df.columns: \n",
    "    if i not in exclude_cols: \n",
    "        feature_cols.add(i[3:])\n",
    "        \n",
    "clean_df['TKCAL'] = clean_df['DR1TKCAL'] + clean_df['DR2TKCAL'] \n",
    "clean_df = clean_df.drop(columns = ['DR1TKCAL', 'DR2TKCAL'])\n",
    "feature_cols.remove(TKCAL)    \n",
    "    \n",
    "for i in feature_cols: \n",
    "    clean_df[i] = clean_df['DR1' + i] + clean_df['DR2' + i] / clean_df['TKCAL']\n",
    "    clean_df = clean_df.drop(columns = ['DR1' + i, \n",
    "                                        'DR2' + i])\n",
    "\n",
    "# format and output to csv \n",
    "clean_df = round(clean_df, 5) \n",
    "clean_df.to_csv(CLEAN_FILE, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
